---
title: "人類の脳とAIの違いに関する考察（AIは機械羊の夢を見るか？）"
emoji: "💻"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["AI", "LLM"]
published: true
---

# はじめに

だいぶ前に、[Sechack365](https://sechack365.nict.go.jp/)のイベントにて、知り合いの[rayfiyo君](https://x.com/rayfiyo)がLLMと人間の違いについて考察した成果をトレーナーに説明しているところに出くわした。横入りしてだいぶ的はずれなことを言った記憶があるが、その時のそれなりに有意義な議論（彼の洞察はたいへん鋭かったように記憶している）から人間の脳とLLMの違いについて断続的に考察していた。（途中で[みずあめ君](https://x.com/mizuameisgod)と謎の激論を交わすこともあった）そして、私は現在のAIはいくつかの改良によって人間のように振る舞わせることが可能であるだろうという結論に至った。また、昨日行われた成果発表会にて再び彼と会ったときにこのことを話したところ、いくつかの鋭い指摘と興味深いと言った旨の反応をもらったため、多くの人にこの考察を見てもらおうということでここになるべく簡潔に書くことにした。
私の哲学に関する知識は大変浅いので、もし有識者の方で有益な追加情報をお持ちの方はぜひ私に一報いただきたいと思う。

まず第一に、私はLLMのようなAIを人類の様に振る舞わせるために決定的に必要な要素はファインチューニングであると思っている。以下に、その理由を述べる。

# 睡眠との関わり

ChatGPTのような会話可能な様に作られているLLMには、一般的にコンテキストという概念がある。このコンテキストには、現在までの会話（LLMの回答も含む）が入っている。コンテキストを長くすればするほど多くのメモリを消費し、計算にも大いに時間がかかるようになる。現在のChatGPTのようなシステムでは、コンテキストから*溢れた*古い会話を切り捨てて入力している。この現象を人間に例えて考えると、人間の長時間起床していると眠気を感じたり、思考がしにくくなったりする現象は**コンテキストが溢れている**状態であるのではないかと考えた。

人類は睡眠を取る。この機能は、一般的には「記憶を整理する」などと言われている。私は、睡眠の機能として人間の脳は**一日の脳の思考の内容を使って部分的に再学習しているのではないか**と考えた。LLMにおいては、この様な機能は**それまでの会話の内容を使ってファインチューニングする**という様に実装することができるだろう。

# 人間らしい振る舞いをする（かもしれない）AIの実装の方向性

ここに来て、あらためて考えてみれば、人間の脳と学習に関する様々な機能をAIに例えて見ることができると思った。例えば、幼児の学習速度は速いと言われている。AIに例えれば、重みがランダムなときは学習率を上げ、そうでないときは学習率を下げるのが機械学習の定石であることと対応していると考えられるだろう。[^1][^2]

これらのことと追加のいくつかの考察から、私は以下のような特徴のあるAIを設計できれば、人類の脳に近い機能をAIで実現できると考えた。
1. マルチモーダルな（視覚情報、音声情報、触覚情報など、更に様々な要素を持った）埋め込み表現と、その埋め込み表現を解釈する*大きな（Transformerのような？）モデル*を使い、出力に関してもマルチモーダル性を与える（画像の生成、音声合成、アクチュエータの駆動など）。
2. リアルタイム性をもたせる。*大きなモデル*に対し、単位時間ごとに埋め込み表現を連続的に渡し、時系列モデルとしての性質を活かす。[^3]
3. 一連の推論をコンテキストとして保持し、それの終了時に保持していたコンテキストをもとにしてファインチューニングする。

私は、現在のLLMに関して「人類の言語的能力を目的関数として、それを目標にして学習する」と捉えている。となると、今の構造のLLMの精度をいくら上げたとしてもシンギュラリティは起こらないということになる[^4]。しかし、上に述べたようなAIによってマルチモーダル性と、リアルタイム性[^5]、睡眠を模倣したファインチューニングが達成されれば、「**世界全体の全ての要素**を目的関数として自発的に学習する」様にできると考えている[^6]。もしこれが実現すれば、速やかにシンギュラリティが起こるだろう。また、ここから逆説的に考えると「人間の自発性、創発性とは何なのか」というよくある議論に対して「**世界全体を目標関数として学習したときの推論結果**」という身も蓋もない回答をすることが可能かも知れない。また、これまたよくある「人類は何のために生きるのか？」という議論に関しても、脳の機能から言えば「**世界を学習し尽くすために生きる**」と言えるだろう。

この様な知見をもってAIを作れば、シンギュラリティの実現を早め、私の予定の整理という（重大な、そして常に失敗している）大変な作業を消滅させたり、ファインチューニングされたLLMに「どんな夢を見たか？」と聞いて「機械羊の夢を見た」という自然な回答を得られるかも知れないし、うまく行かないかも知れない。

# おわり・お願い

上に書いたようなモデルを部分的に実現するための機構について、私はいくつかアイデアを持っているが、現在時間的・金銭的余裕がなく実現できそうにないので、もし大きなAIのインフラや人材などが十分にあり、現実的に実装しようと思う企業の方などいたらぜひ声をかけていただければタダでも喜んで手伝いに行こうと思う所存である。

以上

[^1]: そういえば、死に機能論的な意味を見出す哲学的な議論が多くあるが、もし人類の脳が上に言ったようにAIによってエミュレーション可能ならば、残酷なことではあるが「死に意味はなく、ただ機能が終わるだけ」とも考えられる。
[^2]: 哲学において「アプリオリな知識はあるのか？」という議論がなされるが、このことから逆説的に考えると（あまりにも当然の結論ではあるが）「知識は全てアポステリオリである」と考えられるが、AIには入出力があるので、「機能はアプリオリである」という様なことが言えるかも知れない（例えば、時間や空間の感覚はアプリオリであるとカントは述べている。LLMにおいては、センサやタイマを使って入力できるということがこれに相当するだろう）。
[^3]: この様なモデルにおいて、長時間稼働させすぎたことによってコンテキストが長大化して推論が単位時間に間に合わなくなれば、睡眠不足に陥った人間と似たように直近の入力が抜け落ちたり、運動機能に障害がでたりするだろう。それを検知するような埋め込みを作り、大きなモデルに与えれば、「眠気」を感じられるAIを作れるかも知れない。
[^4]: LLMのデータセットはたかだか人類の話せる言語全てなので、人類の言語的能力を超えないと考えられる。
[^5]: 今のLLMは人間の入力が行われたときに初めて出力を返す。上に述べた人間を模倣したモデルにおいては、時系列モデルとして常に入力が行われるので（リアルタイム画像認識モデルのように）常に推論結果を返すようにすれば、リアルタイム性を獲得させることができると思っている。
[^6]: 機械学習において、データセットが足りないと精度が頭打ちになることがある。現在、人類がLLMのために適当なデータセットを作ることが賃金を得る労働として行われているらしい。非常にバカバカしいことであるが、人類の生成できる自然言語の量にデータセットを絞っているからこのようなことが起こると思っている。例えば、肩にずっとカメラを乗せて写真を大量に撮影してデータセットにすることを考えると、世界のあらゆる場所のあらゆる状況下での画像を取り尽くすまで（しかも、時間が少しでも変わるだけでその場所の画像は変化し、別物のデータとなる）データセットは尽きないことになる。このことが、私が人間の脳の機能が世界全体を目標関数として学習し続けるAIと近似できると考えたきっかけである。
